# Fast Learning

A full-stack conversational AI learning platform similar to ChatGPT, built with Flask and modern web technologies. Features real-time chat with WebSocket support, conversation history, and multiple AI model support.

![Fast Learning](https://img.shields.io/badge/AI-Fast%20Learning-10a37f?style=for-the-badge)
![Python](https://img.shields.io/badge/Python-3.12-blue?style=for-the-badge)
![Flask](https://img.shields.io/badge/Flask-3.0.0-black?style=for-the-badge)
![WebSocket](https://img.shields.io/badge/WebSocket-Enabled-orange?style=for-the-badge)

## âœ¨ Features

### ğŸ¤– AI Capabilities
- **Multiple AI Models**: Support for GPT-3.5, GPT-4, and local Hugging Face models
- **Real-time Streaming**: See AI responses as they're generated
- **Context-Aware**: Maintains conversation history for coherent responses
- **Smart Fallback**: Automatically switches between OpenAI, local models, and rule-based responses

### ğŸ’¬ Chat Features
- **Modern ChatGPT-like UI**: Clean, intuitive interface
- **Conversation Management**: Save, load, and delete chat sessions
- **Message History**: Persistent storage of all conversations
- **Typing Indicators**: Real-time feedback during AI response generation
- **Code Highlighting**: Syntax highlighting for code snippets
- **Markdown Support**: Formatted text with bold, italic, and code blocks

### ğŸ¨ User Experience
- **Dark/Light Theme**: Toggle between themes with persistence
- **Responsive Design**: Works on desktop, tablet, and mobile
- **WebSocket Support**: Real-time bidirectional communication
- **Example Prompts**: Quick-start suggestions for new users
- **Session Persistence**: Conversations saved automatically

## ğŸš€ Quick Start

### Prerequisites
- Python 3.12+
- Virtual environment (recommended)
- Optional: OpenAI API key for GPT models

### Installation

1. **Clone or navigate to the repository**
```bash
cd fast-learning
```

2. **Create and activate virtual environment**
```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Optional: Set OpenAI API key** (for GPT models)
```bash
export OPENAI_API_KEY='your-api-key-here'
```
Or create a `.env` file:
```
OPENAI_API_KEY=your-api-key-here
```

5. **Run the application**
```bash
cd backend
python app.py
```

6. **Open in browser**
```
http://localhost:5000
```

## ğŸ“ Project Structure

```
fast-learning/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                      # Flask application with WebSocket
â”‚   â”œâ”€â”€ conversations/              # Stored conversation JSON files
â”‚   â”œâ”€â”€ models/                     # AI model configurations
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ ai_engine.py           # AI model integration
â”‚       â””â”€â”€ conversation_manager.py # Conversation storage logic
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html                 # Main HTML structure
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ style.css             # Modern UI styling
â”‚   â””â”€â”€ js/
â”‚       â””â”€â”€ app.js                # Frontend logic & WebSocket client
â”œâ”€â”€ data/                          # Additional data storage
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ README.md                      # This file
â”œâ”€â”€ QUICKSTART.md                  # Quick setup guide
â””â”€â”€ LICENSE                        # MIT License
```

## ğŸ”§ Configuration

### AI Models

The platform supports multiple AI providers:

1. **OpenAI (GPT-3.5/GPT-4)**
   - Requires API key in `.env` file
   - Best quality responses
   - Usage charges apply

2. **Hugging Face (Local Models)**
   - Free to use
   - Runs locally (DialoGPT-medium by default)
   - No API key required
   - First run downloads model (~1GB)

3. **Rule-Based Fallback**
   - Always available
   - Pattern-matching responses
   - No setup required

### Environment Variables

Create a `.env` file in the root directory:

```env
# OpenAI Configuration (optional)
OPENAI_API_KEY=your-api-key-here

# Server Configuration
FLASK_ENV=development
FLASK_DEBUG=True
PORT=5000

# Model Settings
DEFAULT_MODEL=gpt-3.5-turbo
MAX_TOKENS=1000
TEMPERATURE=0.7
```

## ğŸŒ API Endpoints

### REST API

- `GET /api/health` - Health check
- `POST /api/chat` - Send message (non-streaming)
- `GET /api/conversations` - List all conversations
- `GET /api/conversations/<id>` - Get specific conversation
- `DELETE /api/conversations/<id>` - Delete conversation
- `POST /api/conversations/clear` - Clear all conversations
- `GET /api/models` - List available AI models

### WebSocket Events

**Client â†’ Server:**
- `send_message` - Send chat message
- `new_conversation` - Create new conversation

**Server â†’ Client:**
- `connected` - Connection established
- `typing` - AI is typing indicator
- `message_chunk` - Streaming response chunk
- `message_complete` - Response finished
- `conversation_created` - New conversation created
- `error` - Error occurred

## ğŸ’¡ Usage Examples

### Basic Chat
1. Open the application in your browser
2. Type a message in the input box
3. Press Enter or click Send
4. Watch the AI response stream in real-time

### Switch AI Models
- Use the dropdown in the header to select different models
- Choose between GPT-3.5, GPT-4, or local models
- Model preference is saved per conversation

### Manage Conversations
- **New Chat**: Click "New Chat" button in sidebar
- **Load Chat**: Click on any conversation in the sidebar
- **Delete Chat**: Hover over conversation and click trash icon
- **Clear All**: Click "Clear All Chats" at bottom of sidebar

### Example Prompts

Try these example prompts:
- "Explain quantum computing in simple terms"
- "Write a Python function to reverse a string"
- "Give me tips for learning AI and machine learning"
- "What are the best practices for web development?"

## ğŸ› ï¸ Technology Stack

### Backend
- **Flask 3.0.0** - Web framework
- **Flask-SocketIO** - WebSocket support
- **OpenAI API** - GPT models integration
- **Transformers** - Hugging Face model support
- **PyTorch** - Deep learning framework
- **NLTK** - Natural language processing

### Frontend
- **HTML5/CSS3** - Modern web standards
- **Vanilla JavaScript** - No framework dependencies
- **Socket.IO Client** - Real-time communication
- **Marked.js** - Markdown rendering
- **Highlight.js** - Code syntax highlighting
- **Font Awesome** - Icon library

## ğŸ“Š Performance

- **Response Time**: < 2s for GPT-3.5, < 5s for local models
- **Streaming**: Real-time chunk delivery
- **Concurrent Users**: Supports multiple simultaneous connections
- **Storage**: JSON-based, scalable to thousands of conversations

## ğŸ”’ Security Notes

- API keys stored in environment variables (never in code)
- CORS enabled for development (configure for production)
- Input sanitization for XSS prevention
- Rate limiting recommended for production deployment

## ğŸš§ Future Enhancements

- [ ] User authentication and multi-user support
- [ ] Database integration (PostgreSQL/MongoDB)
- [ ] Voice input/output
- [ ] Image generation integration (DALL-E)
- [ ] Export conversations (PDF, Markdown, JSON)
- [ ] Custom system prompts
- [ ] Fine-tuned models
- [ ] Analytics dashboard
- [ ] Mobile app (React Native/Flutter)

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¨â€ğŸ’» Author

**Rakesh Reddy Ravula**
- GitHub: [@rakeshreddyravula9-lgtm](https://github.com/rakeshreddyravula9-lgtm)
- Email: rakeshreddyravula9@gmail.com

## ğŸ™ Acknowledgments

- OpenAI for GPT API
- Hugging Face for transformer models
- Flask and Socket.IO communities
- ChatGPT UI inspiration

## ğŸ“§ Support

For issues, questions, or suggestions, please open an issue on GitHub.

---

**Built with â¤ï¸ using Python, Flask, and modern web technologies**
